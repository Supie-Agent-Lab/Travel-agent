# **基于大语言模型的分层多代理动态旅游偏好建模框架**

[Benchmark](https://arxiv.org/pdf/2412.13682)

## **摘要**

针对现有个性化旅游推荐系统中用户偏好建模静态化、难以捕捉深层动机、冷启动困难、缺乏完整方案设计能力等问题，本文提出了一个创新的基于大语言模型（LLM）的动态用户偏好建模框架。该框架通过**对话式交互**构建深度用户画像，创新性地采用**Dropout**机制生成多个子画像代理以增强模型的鲁棒性与探索能力。我们设计了**分层评估（Hierarchical Evaluation）**方法，通过嵌套的基于**Bradley-Terry模型**的成对比较将抽象的"体验"指标量化。最终，框架构建了一个**多元代理委员会（Multi-Agent Committee）**，为用户提供代表其偏好多样性的高质量推荐集合。

---

## **1. 引言**

个性化旅游推荐是智能旅游服务的核心问题。传统方法主要依赖历史行为数据，存在冷启动问题且难以捕捉用户的深层动机和情境化需求。本框架利用大语言模型的自然语言理解和生成能力，通过单次深度对话即可构建丰富的用户模型，并通过多代理机制提供鲁棒的个性化推荐。

---

## **2. 框架概述**

本框架包含两个核心阶段：

### **阶段一：偏好引出与模型拟合**
通过与用户的单次深度交互，从零开始学习并构建代表该用户多面性偏好的决策模型库。

### **阶段二：多元代理推荐**
应用已学习的模型库，为用户的具体旅行需求提供多样化的高质量推荐。

---

## **3. 阶段一：偏好引出与模型拟合**

### **3.1 对话式用户画像构建**

#### **3.1.1 用户特征模型定义**
我们定义了一个四层结构的用户特征模型 $F$：
- $F_{\text{foundational}}$：基础事实（预算范围、同行人员、时间限制等硬约束）
- $F_{\text{behavioral}}$：行为偏好（偏好的活动类型、作息习惯、交通方式等）
- $F_{\text{motivational}}$：深层动机（旅行目的、价值观、情感需求等）
- $F_{\text{contextual}}$：动态情境（季节偏好、当前心情、特殊需求等）

#### **3.1.2 对话流程**
利用经过指令微调的LLM作为对话代理，通过结构化的对话策略逐层探索用户特征：
1. 开放式问题引出基本需求
2. 基于初步回答的针对性深挖
3. 通过假设性场景探测深层偏好
4. 验证和确认关键约束

#### **3.1.3 输出格式**
对话结束后，生成**核心用户画像 $P_{\text{core}}$**，采用自然语言描述的非结构化格式，便于LLM理解和模拟：

```
P_core 示例：
"这是一位35岁的职场妈妈，计划带着丈夫和6岁的女儿进行一次为期3天的北京亲子游。
她们的预算在3000-5000元之间，希望这次旅行既能让孩子增长见识，又能让全家人
都得到放松。她本人对历史文化很感兴趣，但考虑到孩子的接受能力，更倾向于选择
有趣味性和互动性的文化景点。她们一家人都是美食爱好者，特别想尝试地道的北京
小吃。由于带着孩子，她们偏好舒适便捷的出行方式，不希望行程太赶，每天最好
有充足的休息时间。住宿方面希望干净舒适，最好靠近地铁站。这位妈妈特别重视
旅行的教育意义，希望通过这次旅行培养孩子对中国传统文化的兴趣..."
```

### **3.2 基于Dropout的用户画像变体生成**

#### **3.2.1 变体生成策略**
为增强模型鲁棒性并探索偏好边界，我们使用Dropout机制生成 $k$ 个用户画像变体。每个变体通过选择性地省略原始画像中的某些特征，模拟用户在不同情境下的简化决策模式。

#### **3.2.2 实现方法**
使用单次LLM调用同时生成所有变体：

```
变体生成指令：
"基于以下用户画像，生成5个简化版本。每个版本都保留硬性约束（预算、天数、
人员），但选择性地省略不同方面的偏好信息，模拟用户在不同情境下的关注重点。

原始画像：[P_core]

示例：
原始：喜欢历史文化，爱好美食，注重舒适度，希望有教育意义
变体1：爱好美食，注重舒适度，希望有教育意义（省略文化偏好）
变体2：喜欢历史文化，注重舒适度（省略美食和教育）

请生成5个各有侧重的变体："
```

#### **3.2.3 输出**
生成 $k$ 个子用户画像 $\{P_1, P_2, ..., P_k\}$，每个代表用户可能的一个偏好侧面。

### **3.3 代表路线生成与表示**

#### **3.3.1 用户模拟代理构建**
每个子用户画像 $P_i$ 作为系统提示词（System Prompt），指导LLM模拟该用户：

```
System Prompt 示例：
"你需要完全按照以下描述的人物特征来思考和做决策：
[插入 P_i 的完整描述]

在接下来的对话中，请你：
1. 始终以这个人物的视角思考问题
2. 做选择时要符合描述中的偏好和限制
3. 用第一人称表达观点和感受
4. 保持人物特征的一致性"
```

#### **3.3.2 代表路线获取**
代表路线通过多种渠道获取：
1. **LLM生成**：基于用户画像直接生成符合其特征的典型路线
2. **平台爬取**：从小红书、马蜂窝等平台爬取相似用户的真实路线
3. **专家设计**：旅游专家针对典型用户类型设计的经典路线

每个代理 $P_i$ 关联 $m$ 条代表路线 $\{I_{i1}, I_{i2}, ..., I_{im}\}$。

#### **3.3.3 路线表示**
每条路线 $I_{ij}$ 表示为三元组：

$$I_{ij} = (T_{ij}, M_{ij}, E_{ij})$$

其中：
- $T_{ij}$：总时间成本（包括游览时间和交通时间，单位：小时）
- $M_{ij}$：总金钱成本（单位：元）
- $E_{ij}$：景点集合 $\{a_1, a_2, ..., a_s\}$，每个景点包含名称和建议游览时长

### **3.4 分层偏好评估**

#### **3.4.1 全局景点池构建**
从所有 $k \times m$ 条代表路线中提取不重复景点，构建全局景点池：

$$A = \{a_1, a_2, ..., a_p\}$$

#### **3.4.2 景点级评估**
每个子用户画像代理 $P_i$ 对全局景点池进行评估：

1. **成对比较提示**：
```
Prompt:
"基于你的人物设定，请比较以下两个景点，选择你更想去的那个：
景点A：{景点A描述}
景点B：{景点B描述}

请选择：A 或 B"
```

2. **Bradley-Terry建模**：
收集所有成对比较结果，构建比较矩阵 $C_i$，使用Bradley-Terry模型：

$$P(a_j > a_k | P_i) = \frac{\pi_{ij}}{\pi_{ij} + \pi_{ik}}$$

通过最大似然估计求解每个景点的体验值 $\pi_{ij}$

3. **归一化**：将体验值归一化为评分 $\text{score}_i(a_j) \in [0, 1]$

#### **3.4.3 路线体验分计算**
对每条路线 $I_{ij}$，计算其聚合体验分：

$$\text{Experience}_{ij} = \sum_{a \in E_{ij}} w(a) \times \text{score}_i(a)$$

其中 $w(a)$ 为景点权重：

$$w(a) = \frac{\text{duration}(a)}{\sum_{a' \in E_{ij}} \text{duration}(a')}$$

#### **3.4.4 路线级评估**
每个代理 $P_i$ 对其 $m$ 条完整路线进行成对比较：

1. **路线比较提示**：
```
Prompt:
"基于你的人物设定，请比较以下两条完整的旅行路线：
路线A：[包含景点列表、时间、费用等完整信息]
路线B：[包含景点列表、时间、费用等完整信息]

请选择你更喜欢的路线：A 或 B"
```

2. 应用Bradley-Terry模型，得到每条路线的综合奖励值 $R_{ij}$

### **3.5 效用函数拟合**

#### **3.5.1 模型定义**
采用线性效用模型：

$$R = W_T \times T + W_M \times M + W_E \times \text{Experience}$$

#### **3.5.2 参数估计**
对每个代理 $P_i$，基于样本集 $\{(R_{ij}, T_{ij}, M_{ij}, \text{Experience}_{ij})\}$，使用普通最小二乘法（OLS）估计权重：

$$W_i = (W_{T,i}, W_{M,i}, W_{E,i}) = \arg\min_W \sum_j (R_{ij} - \hat{R}_{ij})^2$$

#### **3.5.3 输出**
得到 $k$ 组权重向量 $\{W_1, W_2, ..., W_k\}$，构成用户的完整决策模型库。

---

## **4. 阶段二：多元代理推荐**

### **4.1 候选空间生成**
根据用户的具体需求（目的地、时间等），大规模生成候选路线集合 $\{S_1, S_2, ..., S_n\}$，其中 $n \gg m$。

### **4.2 并行效用计算**
每个代理 $P_i$ 使用其权重 $W_i$ 对所有候选路线进行评分：

$$U_i(S_j) = W_{T,i} \times T_j + W_{M,i} \times M_j + W_{E,i} \times \text{Experience}_j$$

### **4.3 委员会推荐**
1. 每个代理选出其评分最高的路线作为"冠军方案"
2. 去重后得到最终推荐集 $\{S^*_1, S^*_2, ..., S^*_l\}$，其中 $l \leq k$
3. 为每个推荐附加解释，说明其代表的用户偏好维度

---

## **5. 实验设计与评估**

### **5.1 数据集**
- 用户对话数据：通过众包收集100个用户的深度对话
- 路线数据：从旅游平台爬取1000+条真实路线
- 景点数据：包含500+个景点的详细信息

### **5.2 评估指标**
- **覆盖度**：推荐集合对用户偏好空间的覆盖程度
- **多样性**：推荐路线之间的差异度
- **满意度**：用户对推荐结果的主观评分
- **鲁棒性**：面对偏好不确定性时的推荐稳定性

### **5.3 基线方法**
- 协同过滤（CF）
- 基于内容的推荐（CBR）
- 深度学习方法（如Wide & Deep）
- 单一LLM生成（无多代理机制）

---

## **6. 拓展课题**

### **6.1 景点组合效应建模**
当前框架采用简单的加权求和计算路线体验分，忽略了景点间的组合效应。未来可以考虑：
- **多样性奖励**：基于景点类别分布的多样性度量
- **主题一致性**：评估路线的主题连贯性
- **序列依赖**：考虑游览顺序对体验的影响
- **协同效应**：建模景点间的正向或负向交互

### **6.2 动态偏好更新**
基于用户的实际选择和反馈，动态更新用户画像和偏好模型。

### **6.3 群体决策支持**
扩展框架以支持多人出行的群体决策，考虑不同成员偏好的平衡。

---

## **7. 结论**

本文提出的分层多代理动态旅游偏好建模框架，通过对话式交互和Dropout机制有效解决了用户偏好的获取和建模问题。框架的创新点在于：（1）使用自然语言形式的用户画像，充分利用LLM的语言理解能力；（2）通过Dropout生成多个代理，提高推荐的鲁棒性；（3）分层评估方法有效量化抽象的体验指标；（4）多代理委员会机制提供多样化推荐。
